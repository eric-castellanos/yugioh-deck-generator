name: Terraform Infrastructure

on:
  workflow_dispatch:
    inputs:
      recreate:
        description: 'Recreate existing resources if they exist'
        required: false
        default: 'false'
        type: boolean
      action:
        description: 'Action to perform (plan/apply/destroy)'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
      environment:
        description: 'Environment (dev/prod)'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - prod
      source_dir:
        description: 'Source directory for Terraform files'
        required: true
        default: 'infra/terraform'
        type: string
  pull_request:
    branches:
      - infra/setup_ml_flow
  push:
    branches:
      - infra/setup_ml_flow

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-east-1

jobs:
  terraform:
    runs-on: ubuntu-latest
    env:
      TF_ACTION: ${{ github.event.inputs.action || 'plan' }}
      TF_SOURCE_DIR: ${{ github.event.inputs.source_dir || 'infra/terraform' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Copy Terraform files safely
        run: |
          # Use dispatch input if available, or fallback to default
          INPUT_SOURCE_DIR="${{ inputs.source_dir }}"
          FALLBACK_DIR="infra/terraform"

          if [ -z "$INPUT_SOURCE_DIR" ]; then
            echo "No input for source_dir detected. Defaulting to: $FALLBACK_DIR"
            SOURCE_DIR="${GITHUB_WORKSPACE}/$FALLBACK_DIR"
          else
            SOURCE_DIR="${GITHUB_WORKSPACE}/$INPUT_SOURCE_DIR"
          fi

          TARGET_DIR="${GITHUB_WORKSPACE}/target-terraform"

          echo "SOURCE: $SOURCE_DIR"
          echo "TARGET: $TARGET_DIR"

          if [ "$SOURCE_DIR" == "$TARGET_DIR" ]; then
            echo "ERROR: Source and target directories are the same. Aborting."
            exit 1
          fi

          mkdir -p "$TARGET_DIR"
          cp -r "$SOURCE_DIR/." "$TARGET_DIR/"

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.6.0

      - name: Get Database Password
        id: get_password
        run: |
          # Check if the secret already exists
          SECRET_NAME="mlflow-db-password-${{ github.event.inputs.environment || 'dev' }}"
          
          # Try to get the existing secret
          SECRET=$(aws secretsmanager get-secret-value \
            --secret-id "$SECRET_NAME" \
            --query SecretString \
            --output text 2>/dev/null)
          
          # If secret doesn't exist, create a new one
          if [ $? -ne 0 ]; then
            echo "No existing secret found, generating new password..."
            DB_PASSWORD=$(openssl rand -base64 32)
            
            # Store the password in AWS Secrets Manager
            aws secretsmanager create-secret \
              --name "$SECRET_NAME" \
              --description "MLFlow Database Password for ${{ github.event.inputs.environment || 'dev' }} environment" \
              --secret-string "$DB_PASSWORD"
            
            echo "DB_PASSWORD=$DB_PASSWORD" >> $GITHUB_ENV
          else
            # Use existing secret
            echo "Using existing secret..."
            echo "DB_PASSWORD=$SECRET" >> $GITHUB_ENV
          fi
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}

      - name: Check Existing VPCs
        id: check_vpc
        run: |
          # Check if VPC with the same name already exists
          VPC_NAME="mlflow-vpc-${{ github.event.inputs.environment || 'dev' }}"
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Project,Values=mlflow" "Name=tag:Environment,Values=${{ github.event.inputs.environment || 'dev' }}" --query 'Vpcs[0].VpcId' --output text)
          
          if [ -n "$VPC_ID" ]; then
            echo "Found existing VPC: $VPC_ID"
            echo "VPC_EXISTS=true" >> $GITHUB_OUTPUT
            echo "VPC_ID=$VPC_ID" >> $GITHUB_OUTPUT
            
            # Get existing subnets
            PUBLIC_SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Type,Values=public" --query 'Subnets[*].SubnetId' --output json)
            PRIVATE_SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Type,Values=private" --query 'Subnets[*].SubnetId' --output json)
            echo "PUBLIC_SUBNET_IDS=$PUBLIC_SUBNETS" >> $GITHUB_OUTPUT
            echo "PRIVATE_SUBNET_IDS=$PRIVATE_SUBNETS" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "VPC_EXISTS=false" >> $GITHUB_OUTPUT
        working-directory: ${{ github.workspace }}/${{ inputs.source_dir || 'infra/terraform/vpc' }}

      - name: Check VPC Limits and Cleanup
        run: |
          echo "Checking VPC limits and cleaning up..."
          aws ec2 describe-vpcs --query 'Vpcs[*].[VpcId]' --output text | while read -r vpc_id; do
            if [[ -n "$vpc_id" && "$vpc_id" =~ ^vpc- ]]; then
              echo "Found VPC: $vpc_id"

              # Delete all subnets with dependency handling
              echo "Getting subnets for VPC: $vpc_id"
              subnets=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$vpc_id" --query 'Subnets[*].[SubnetId]' --output text)
              IFS=$'\t' read -r -a subnet_ids <<< "$subnets"
              for subnet in "${subnet_ids[@]}"; do
                if [[ -n "$subnet" && "$subnet" =~ ^subnet- ]]; then
                  echo "Processing subnet: $subnet"

                  dependencies=$(aws ec2 describe-network-interfaces --filters Name=subnet-id,Values=$subnet --query 'NetworkInterfaces[*].[NetworkInterfaceId]' --output text)
                  for eni in $dependencies; do
                    echo "Deleting network interface: $eni"
                    aws ec2 delete-network-interface --network-interface-id "$eni" || echo "Could not delete ENI $eni"
                  done

                  nat_gws=$(aws ec2 describe-nat-gateways --filter "Name=subnet-id,Values=$subnet" --query 'NatGateways[*].NatGatewayId' --output text)
                  for ngw in $nat_gws; do
                    echo "Deleting NAT gateway: $ngw"
                    aws ec2 delete-nat-gateway --nat-gateway-id "$ngw" || echo "Could not delete NAT gateway $ngw"
                  done

                  echo "Attempting to delete subnet: $subnet"
                  aws ec2 delete-subnet --subnet-id "$subnet" || echo "Subnet $subnet could not be deleted (dependencies may still exist)"
                else
                  echo "Skipping invalid subnet ID: $subnet"
                fi
              done

              echo "Waiting 10 seconds after subnet cleanup..."
              sleep 10

              # Delete non-default security groups
              echo "Getting security groups for VPC: $vpc_id"
              aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$vpc_id" --query "SecurityGroups[?GroupName!='default'].GroupId" --output text | tr '\t' '\n' | while read -r sg; do
                if [[ -n "$sg" && "$sg" =~ ^sg- ]]; then
                  echo "Processing security group: $sg"
                  retries=3
                  while [[ $retries -gt 0 ]]; do
                    # Check for attached ENIs
                    attached_enis=$(aws ec2 describe-network-interfaces --filters Name=group-id,Values=$sg --query 'NetworkInterfaces[*].NetworkInterfaceId' --output text)
                    if [[ -n "$attached_enis" ]]; then
                      echo "Security group $sg has attached ENIs: $attached_enis"
                      for eni in $attached_enis; do
                        echo "Attempting to delete ENI $eni..."
                        aws ec2 delete-network-interface --network-interface-id "$eni" || echo "Could not delete ENI $eni (still in use)"
                      done
                      echo "Waiting 5 seconds after ENI cleanup..."
                      sleep 5
                    fi

                    # Check for instances using this security group
                    instances=$(aws ec2 describe-instances --filters "Name=network-interface.group-id,Values=$sg" --query 'Reservations[*].Instances[*].[InstanceId]' --output text)
                    if [[ -n "$instances" ]]; then
                      echo "Security group $sg is still used by instances: $instances"
                      echo "Waiting 10 seconds for instances to terminate..."
                      sleep 10
                    fi

                    # Try to delete the security group
                    echo "Attempting to delete security group: $sg (attempt $((4 - retries)))"
                    if aws ec2 delete-security-group --group-id "$sg" 2>/dev/null; then
                      echo "Successfully deleted security group: $sg"
                      break
                    else
                      echo "Failed to delete security group $sg, retrying..."
                      sleep 5
                      retries=$((retries - 1))
                    fi
                  done

                  if [[ $retries -eq 0 ]]; then
                    echo "Could not delete security group $sg after multiple attempts"
                  fi
                fi
              done

              # Get route tables and process each one
              echo "Getting route tables for VPC: $vpc_id"
              aws ec2 describe-route-tables --filters "Name=vpc-id,Values=$vpc_id" --query 'RouteTables[*].RouteTableId' --output text | tr '\t' '\n' | while read -r rt; do
                if [[ -n "$rt" && "$rt" =~ ^rtb- ]]; then
                  echo "Processing route table: $rt"

                  main_assoc_id=$(aws ec2 describe-route-tables --route-table-ids "$rt" --query 'RouteTables[0].Associations[?Main==`true`].RouteTableAssociationId' --output text)
                  if [[ -n "$main_assoc_id" ]]; then
                    echo "Route table $rt is main, creating temporary replacement..."
                    temp_rt=$(aws ec2 create-route-table --vpc-id "$vpc_id" --query 'RouteTable.RouteTableId' --output text)
                    aws ec2 replace-route-table-association --association-id "$main_assoc_id" --route-table-id "$temp_rt"
                    echo "Main route table replaced with $temp_rt"
                  fi

                  associations=$(aws ec2 describe-route-tables --route-table-ids "$rt" --query 'RouteTables[0].Associations[?Main==`false`].RouteTableAssociationId' --output text)
                  for assoc in $associations; do
                    echo "Disassociating route table from subnet (assoc ID: $assoc)"
                    aws ec2 disassociate-route-table --association-id "$assoc"
                  done

                  aws ec2 describe-route-tables --route-table-ids "$rt" --query 'RouteTables[0].Routes[?GatewayId!=`local`].[DestinationCidrBlock,GatewayId]' --output text | while read -r dest gw; do
                    if [[ -n "$dest" && -n "$gw" ]]; then
                      echo "Deleting route: $dest (Gateway: $gw) from route table: $rt"
                      aws ec2 delete-route --route-table-id "$rt" --destination-cidr-block "$dest"
                    fi
                  done

                  echo "Deleting route table: $rt"
                  aws ec2 delete-route-table --route-table-id "$rt" || echo "Route table $rt could not be deleted (dependencies may still exist)"
                else
                  echo "Skipping invalid route table ID: $rt"
                fi
              done

              # Delete non-default NACLs
              echo "Getting NACLs for VPC: $vpc_id"
              nacls=$(aws ec2 describe-network-acls --filters "Name=vpc-id,Values=$vpc_id" --query 'NetworkAcls[?IsDefault==`false`].NetworkAclId' --output text)
              if [[ -n "$nacls" ]]; then
                for nacl_id in $nacls; do
                  echo "Deleting network ACL: $nacl_id"
                  retries=3
                  while [[ $retries -gt 0 ]]; do
                    if aws ec2 delete-network-acl --network-acl-id "$nacl_id" 2>/dev/null; then
                      echo "Successfully deleted NACL: $nacl_id"
                      break
                    else
                      echo "Failed to delete NACL $nacl_id, retrying... ($retries attempts left)"
                      sleep 5
                      retries=$((retries - 1))
                    fi
                  done
                  if [[ $retries -eq 0 ]]; then
                    echo "Could not delete NACL $nacl_id after multiple attempts"
                  fi
                done
              else
                echo "No non-default NACLs found"
              fi

              echo "Deleting VPC: $vpc_id"
              aws ec2 delete-vpc --vpc-id "$vpc_id" || echo "VPC $vpc_id could not be deleted (dependencies may still exist)"

              echo "Waiting 10 seconds after VPC deletion..."
              sleep 10
            else
              echo "Skipping invalid VPC ID: $vpc_id"
            fi
          done
        working-directory: ${{ github.workspace }}/${{ inputs.source_dir || 'infra/terraform/vpc' }}

      - name: Create VPC Infrastructure
        if: steps.check_vpc.outputs.VPC_EXISTS != 'true'
        run: |
          # Set environment variables
          ENVIRONMENT="${{ github.event.inputs.environment || 'dev' }}"
          
          # Initialize Terraform
          echo "Initializing Terraform..."
          terraform init
          
          # Check for existing state
          if [[ -f terraform.tfstate ]]; then
            echo "State file exists, checking for existing resources..."
            
            # Get existing resources
            existing_vpc=$(terraform state list | grep aws_vpc | cut -d'.' -f2)
            existing_subnets=$(terraform state list | grep aws_subnet | cut -d'.' -f2)
            
            if [[ -n "$existing_vpc" ]]; then
              echo "Found existing VPC: $existing_vpc"
              
              # Check if we need to recreate
              recreate=${{ github.event.inputs.recreate || 'false' }}
              if [[ "$recreate" == 'true' ]]; then
                echo "Recreating resources..."
                terraform destroy -auto-approve
                terraform plan -out=tfplan
                terraform apply -auto-approve tfplan
              else
                echo "Skipping recreation of existing resources"
                exit 0
              fi
            else
              echo "No existing resources found, creating new..."
              terraform plan -out=tfplan
              terraform apply -auto-approve tfplan
            fi
          else
            echo "No state file found, creating new resources..."
            terraform plan -out=tfplan
            terraform apply -auto-approve tfplan
          fi
          
          # Get VPC ID
          VPC_ID=$(terraform output -json | jq -r '.vpc_id.value')
          
          # Get subnet IDs
          PUBLIC_SUBNETS=$(terraform output -json | jq -r '.public_subnet_ids.value | map(tostring) | join(",")')
          PRIVATE_SUBNETS=$(terraform output -json | jq -r '.private_subnet_ids.value | map(tostring) | join(",")')
          
          # Output values
          echo "VPC_EXISTS=true" >> $GITHUB_OUTPUT
          echo "VPC_ID=$VPC_ID" >> $GITHUB_OUTPUT
          echo "PUBLIC_SUBNET_IDS=$PUBLIC_SUBNETS" >> $GITHUB_OUTPUT
          echo "PRIVATE_SUBNET_IDS=$PRIVATE_SUBNETS" >> $GITHUB_OUTPUT
        working-directory: ${{ github.workspace }}/${{ inputs.source_dir || 'infra/terraform/vpc' }}

      - name: Get VPC Outputs
        if: steps.check_vpc.outputs.VPC_EXISTS != 'true'
        id: vpc_outputs
        run: |
          outputs=$(terraform output -json)
          echo "VPC_ID=$(echo $outputs | jq -r '.vpc_id.value')" >> $GITHUB_OUTPUT
          echo "PUBLIC_SUBNET_IDS=$(echo $outputs | jq -r '.public_subnets.value | @json')" >> $GITHUB_OUTPUT
          echo "PRIVATE_SUBNET_IDS=$(echo $outputs | jq -r '.private_subnets.value | @json')" >> $GITHUB_OUTPUT
        working-directory: ${{ github.workspace }}/${{ inputs.source_dir || 'infra/terraform/vpc' }}

      - name: Configure MLFlow Terraform
        run: |
          # Set fallback values if inputs are not defined (non-manual runs)
          ENVIRONMENT="${{ github.event.inputs.environment || 'dev' }}"
          CLUSTER_NAME="mlflow-cluster-${ENVIRONMENT}"

      - name: Configure MLFlow Terraform
        run: |
          # Create terraform.tfvars using VPC outputs
          cat > terraform.tfvars <<EOF
          environment = "${{ github.event.inputs.environment || 'dev' }}"
          cluster_name = "mlflow-cluster-${{ github.event.inputs.environment || 'dev' }}"
          db_password = "${{ env.DB_PASSWORD }}"
          region = "${{ env.AWS_REGION }}"
          EOF
          
          # Initialize and plan
          terraform init
          terraform plan -out=tfplan
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Set VPC Variables
        run: |
          # Set VPC variables based on whether we created a new VPC or using existing
          if [ "${{ steps.check_vpc.outputs.VPC_EXISTS }}" = "true" ]; then
            echo "VPC_ID=${{ steps.check_vpc.outputs.VPC_ID }}" >> $GITHUB_ENV
            echo "PUBLIC_SUBNET_IDS=${{ steps.check_vpc.outputs.PUBLIC_SUBNET_IDS }}" >> $GITHUB_ENV
            echo "PRIVATE_SUBNET_IDS=${{ steps.check_vpc.outputs.PRIVATE_SUBNET_IDS }}" >> $GITHUB_ENV
          else
            echo "VPC_ID=${{ steps.vpc_outputs.outputs.VPC_ID }}" >> $GITHUB_ENV
            echo "PUBLIC_SUBNET_IDS=${{ steps.vpc_outputs.outputs.PUBLIC_SUBNET_IDS }}" >> $GITHUB_ENV
            echo "PRIVATE_SUBNET_IDS=${{ steps.vpc_outputs.outputs.PRIVATE_SUBNET_IDS }}" >> $GITHUB_ENV
          fi
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}

      - name: Import Existing Resources
        if: ${{ env.TF_ACTION == 'apply' && github.event.inputs.recreate == 'true' }}
        run: |
          terraform import aws_db_subnet_group.mlflow mlflow-db-subnet-group-dev
          terraform import aws_s3_bucket.mlflow_bucket mlflow-backend
          terraform import aws_iam_user.mlflow_user user
          terraform import aws_iam_policy.mlflow_s3_policy mlflow-s3-access
          terraform import aws_cloudwatch_log_group.eks ${AWS_REGION}_aws_eks_${{ github.event.inputs.environment }}_cluster
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Apply
        if: ${{ env.TF_ACTION == 'apply' }}
        run: terraform apply -auto-approve tfplan
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Plan
        if: ${{ env.TF_ACTION == 'plan' }}
        run: terraform plan -out=tfplan
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Destroy
        if: ${{ env.TF_ACTION == 'destroy' }}
        run: terraform destroy -auto-approve
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Save Terraform State
        if: ${{ env.TF_ACTION == 'apply' }}
        uses: actions/upload-artifact@v4
        with:
          name: terraform-state
          path: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}/terraform.tfstate

      - name: Get Outputs
        if: ${{ env.TF_ACTION == 'apply' }}
        run: |
          terraform output -json > terraform-outputs.json
          cat terraform-outputs.json
        id: get_outputs
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Save Outputs
        if: ${{ env.TF_ACTION == 'apply' }}
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}/terraform-outputs.json

      - name: Cleanup
        if: ${{ env.TF_ACTION == 'destroy' }}
        run: |
          rm -f terraform.tfstate
          rm -f terraform.tfstate.backup
          rm -f terraform.tfvars
          rm -f terraform-outputs.json
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}
