name: Terraform Infrastructure

on:
  workflow_dispatch:
    inputs:
      recreate:
        description: 'Recreate existing resources if they exist'
        required: false
        default: false
        type: boolean
      action:
        description: 'Action to perform (plan/apply/destroy)'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
      environment:
        description: 'Environment (dev/prod)'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - prod
      source_dir:
        description: 'Source directory for Terraform files'
        required: true
        default: 'infra/terraform'
        type: string
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-east-1

jobs:
  terraform:
    name: Terraform
    runs-on: ubuntu-latest
    env:
      TF_ACTION: ${{ github.event.inputs.action || 'plan' }}
      TF_SOURCE_DIR: ${{ github.event.inputs.source_dir || 'infra/terraform' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.6.0

      - name: Create terraform.tfvars
        run: |
          cat > terraform.tfvars <<EOF
          environment = "${{ github.event.inputs.environment }}"
          cluster_name = "mlflow-cluster-${{ github.event.inputs.environment }}"
          db_password = "${{ secrets.DB_PASSWORD }}"
          region = "${{ env.AWS_REGION }}"
          bucket_name = "mlflow-backend-${{ github.event.inputs.environment }}"
          mlflow_user = "mlflow-user-${{ github.event.inputs.environment }}"
          EOF
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Init
        run: terraform init -upgrade
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Import existing resources
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.recreate == false }}
        run: |
          set +e  # Continue on errors
          
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Project,Values=mlflow" "Name=tag:Environment,Values=${{ github.event.inputs.environment }}" --query 'Vpcs[0].VpcId' --output text)
          if [ "$VPC_ID" != "None" ] && [ -n "$VPC_ID" ]; then
            echo "Importing VPC: $VPC_ID"
            terraform import module.vpc.module.vpc.aws_vpc.this[0] "$VPC_ID" || echo "Failed to import VPC, but continuing"
            
            SUBNETS_JSON=$(aws ec2 describe-subnets \
              --filters "Name=vpc-id,Values=$VPC_ID" \
              --query "Subnets[*].{Id:SubnetId,Name:Tags[?Key=='Name']|[0].Value}" \
              --output json)
            i=0
            for row in $(echo "$SUBNETS_JSON" | jq -c '.[]'); do
              SUBNET_ID=$(echo "$row" | jq -r '.Id')
              NAME=$(echo "$row" | jq -r '.Name')
              if [[ "$NAME" == *"public"* ]]; then
                echo "Importing public subnet: $SUBNET_ID"
                terraform import "module.vpc.module.vpc.aws_subnet.public[${i}]" "$SUBNET_ID" || echo "Failed to import subnet, continuing"
              elif [[ "$NAME" == *"private"* ]]; then
                echo "Importing private subnet: $SUBNET_ID"
                terraform import "module.vpc.module.vpc.aws_subnet.private[${i}]" "$SUBNET_ID" || echo "Failed to import subnet, continuing"
              else
                echo "Skipping subnet $SUBNET_ID with unknown name '$NAME'"
                continue
              fi
              i=$((i+1))
            done
            
            IGW_ID=$(aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=$VPC_ID" --query 'InternetGateways[0].InternetGatewayId' --output text)
            if [ "$IGW_ID" != "None" ] && [ -n "$IGW_ID" ]; then
              echo "Importing Internet Gateway: $IGW_ID"
              terraform import module.vpc.module.vpc.aws_internet_gateway.this[0] "$IGW_ID" || echo "Failed to import IGW, continuing"
            fi
          fi

          echo "Checking S3 bucket..."
          if aws s3api head-bucket --bucket mlflow-backend-${{ github.event.inputs.environment }} 2>/dev/null; then
            echo "Importing S3 bucket: mlflow-backend-${{ github.event.inputs.environment }}"
            terraform import module.s3.aws_s3_bucket.mlflow_bucket mlflow-backend-${{ github.event.inputs.environment }} || echo "Failed to import S3 bucket, continuing"
          fi

          echo "Checking IAM user..."
          if aws iam get-user --user-name mlflow-user-${{ github.event.inputs.environment }} 2>/dev/null; then
            echo "Importing IAM user: mlflow-user-${{ github.event.inputs.environment }}"
            terraform import module.s3.aws_iam_user.mlflow_user mlflow-user-${{ github.event.inputs.environment }} || echo "Failed to import IAM user, continuing"
          fi
          
          echo "Checking IAM policy..."
          POLICY_ARN=$(aws iam list-policies --query "Policies[?PolicyName=='mlflow-s3-access'].Arn" --output text)
          if [ -n "$POLICY_ARN" ] && [ "$POLICY_ARN" != "None" ]; then
            echo "Importing IAM policy: $POLICY_ARN"
            terraform import module.s3.aws_iam_policy.mlflow_s3_policy "$POLICY_ARN" || echo "Failed to import IAM policy, continuing"
          fi

          echo "Checking CloudWatch log group..."
          if aws logs describe-log-groups --log-group-name /aws/eks/mlflow-cluster-${{ github.event.inputs.environment }}/cluster --query 'logGroups[0].logGroupName' --output text 2>/dev/null | grep -q .; then
            echo "Importing CloudWatch log group"
            terraform import module.eks.module.eks.aws_cloudwatch_log_group.this[0] /aws/eks/mlflow-cluster-${{ github.event.inputs.environment }}/cluster || echo "Failed to import CloudWatch log group, continuing"
          fi

          echo "Checking KMS alias..."
          if aws kms list-aliases --query "Aliases[?AliasName=='alias/eks/mlflow-cluster-${{ github.event.inputs.environment }}'].TargetKeyId" --output text | grep -q .; then
            echo "Importing KMS alias"
            terraform import 'module.eks.module.eks.module.kms.aws_kms_alias.this["cluster"]' alias/eks/mlflow-cluster-${{ github.event.inputs.environment }} || echo "Failed to import KMS alias, continuing"
          fi

          echo "Checking DB subnet group..."
          if aws rds describe-db-subnet-groups --db-subnet-group-name mlflow-db-subnet-group-${{ github.event.inputs.environment }} 2>/dev/null; then
            echo "Importing DB subnet group"
            terraform import module.rds.aws_db_subnet_group.mlflow mlflow-db-subnet-group-${{ github.event.inputs.environment }} || echo "Failed to import DB subnet group, continuing"
          fi

          echo "Checking security group..."
          SG_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=mlflow-rds-sg-${{ github.event.inputs.environment }}" --query 'SecurityGroups[0].GroupId' --output text)
          if [ "$SG_ID" != "None" ] && [ -n "$SG_ID" ]; then
            echo "Importing security group: $SG_ID"
            terraform import module.rds.aws_security_group.mlflow_rds_sg "$SG_ID" || echo "Failed to import security group, continuing"
          fi
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Plan
        if: ${{ env.TF_ACTION == 'plan' }}
        run: terraform plan -input=false -var-file=terraform.tfvars
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Apply
        if: ${{ env.TF_ACTION == 'apply' }}
        run: terraform apply -auto-approve -input=false -var-file=terraform.tfvars
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Destroy
        if: ${{ env.TF_ACTION == 'destroy' }}
        run: terraform destroy -auto-approve -input=false -var-file=terraform.tfvars
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}
