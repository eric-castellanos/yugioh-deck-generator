name: Terraform Infrastructure

on:
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform (plan/apply/destroy)'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
      environment:
        description: 'Environment (dev/prod)'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - prod
      source_dir:
        description: 'Source directory for Terraform files'
        required: true
        default: 'infra/terraform'
        type: string
  pull_request:
    branches:
      - infra/setup_ml_flow
  push:
    branches:
      - infra/setup_ml_flow

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-east-1

jobs:
  terraform:
    runs-on: ubuntu-latest
    env:
      TF_ACTION: ${{ github.event.inputs.action || 'plan' }}
      TF_SOURCE_DIR: ${{ github.event.inputs.source_dir || 'infra/terraform' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Copy Terraform files safely
        run: |
          # Use dispatch input if available, or fallback to default
          INPUT_SOURCE_DIR="${{ inputs.source_dir }}"
          FALLBACK_DIR="infra/terraform"

          if [ -z "$INPUT_SOURCE_DIR" ]; then
            echo "No input for source_dir detected. Defaulting to: $FALLBACK_DIR"
            SOURCE_DIR="${GITHUB_WORKSPACE}/$FALLBACK_DIR"
          else
            SOURCE_DIR="${GITHUB_WORKSPACE}/$INPUT_SOURCE_DIR"
          fi

          TARGET_DIR="${GITHUB_WORKSPACE}/target-terraform"

          echo "SOURCE: $SOURCE_DIR"
          echo "TARGET: $TARGET_DIR"

          if [ "$SOURCE_DIR" == "$TARGET_DIR" ]; then
            echo "ERROR: Source and target directories are the same. Aborting."
            exit 1
          fi

          mkdir -p "$TARGET_DIR"
          cp -r "$SOURCE_DIR/." "$TARGET_DIR/"

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.6.0

      - name: Get Database Password
        id: get_password
        run: |
          # Check if the secret already exists
          SECRET_NAME="mlflow-db-password-${{ github.event.inputs.environment || 'dev' }}"
          
          # Try to get the existing secret
          SECRET=$(aws secretsmanager get-secret-value \
            --secret-id "$SECRET_NAME" \
            --query SecretString \
            --output text 2>/dev/null)
          
          # If secret doesn't exist, create a new one
          if [ $? -ne 0 ]; then
            echo "No existing secret found, generating new password..."
            DB_PASSWORD=$(openssl rand -base64 32)
            
            # Store the password in AWS Secrets Manager
            aws secretsmanager create-secret \
              --name "$SECRET_NAME" \
              --description "MLFlow Database Password for ${{ github.event.inputs.environment || 'dev' }} environment" \
              --secret-string "$DB_PASSWORD"
            
            echo "DB_PASSWORD=$DB_PASSWORD" >> $GITHUB_ENV
          else
            # Use existing secret
            echo "Using existing secret..."
            echo "DB_PASSWORD=$SECRET" >> $GITHUB_ENV
          fi
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}

      - name: Check Existing VPCs
        id: check_vpc
        run: |
          # Check if VPC with the same name already exists
          VPC_NAME="mlflow-vpc-${{ github.event.inputs.environment || 'dev' }}"
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Project,Values=mlflow" "Name=tag:Environment,Values=${{ github.event.inputs.environment || 'dev' }}" --query 'Vpcs[0].VpcId' --output text)
          
          if [ -n "$VPC_ID" ]; then
            echo "Found existing VPC: $VPC_ID"
            echo "VPC_EXISTS=true" >> $GITHUB_OUTPUT
            echo "VPC_ID=$VPC_ID" >> $GITHUB_OUTPUT
            
            # Get existing subnets
            PUBLIC_SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Type,Values=public" --query 'Subnets[*].SubnetId' --output json)
            PRIVATE_SUBNETS=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$VPC_ID" "Name=tag:Type,Values=private" --query 'Subnets[*].SubnetId' --output json)
            echo "PUBLIC_SUBNET_IDS=$PUBLIC_SUBNETS" >> $GITHUB_OUTPUT
            echo "PRIVATE_SUBNET_IDS=$PRIVATE_SUBNETS" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "VPC_EXISTS=false" >> $GITHUB_OUTPUT
        working-directory: ${{ github.workspace }}/${{ inputs.source_dir || 'infra/terraform/vpc' }}

      - name: Check VPC Limits and Cleanup
        run: |
          echo "Checking VPC limits and cleaning up..."
          
          aws ec2 describe-vpcs --query 'Vpcs[*].[VpcId]' --output text | while read -r vpc_id; do
            echo "Found VPC: $vpc_id"
            
            # Delete all subnets
            subnets=$(aws ec2 describe-subnets --filters "Name=vpc-id,Values=$vpc_id" --query 'Subnets[*].[SubnetId]' --output text)
            for subnet in $subnets; do
              echo "Deleting subnet: $subnet"
              aws ec2 delete-subnet --subnet-id "$subnet"
            done
            
            # Delete non-default security groups
            echo "Getting security groups for VPC: $vpc_id"
            aws ec2 describe-security-groups --filters "Name=vpc-id,Values=$vpc_id" --query 'SecurityGroups[*].[GroupId,GroupName]' --output text | while read -r sg name; do
              if [[ -n "$sg" && "$sg" =~ ^sg- ]]; then
                echo "Found security group: $sg ($name)"
                if [[ "$name" != "default" ]]; then
                  echo "Deleting security group: $sg"
                  aws ec2 delete-security-group --group-id "$sg"
                else
                  echo "Skipping default security group: $sg"
                fi
              fi
            done
            
            # Delete internet gateways
            igs=$(aws ec2 describe-internet-gateways --filters "Name=attachment.vpc-id,Values=$vpc_id" --query 'InternetGateways[*].[InternetGatewayId]' --output text)
            for ig in $igs; do
              echo "Detaching internet gateway: $ig"
              aws ec2 detach-internet-gateway --internet-gateway-id "$ig" --vpc-id "$vpc_id"
              echo "Deleting internet gateway: $ig"
              aws ec2 delete-internet-gateway --internet-gateway-id "$ig"
            done
            
            # Route tables cleanup
            echo "Getting route tables for VPC: $vpc_id"
            # First get all route table IDs
            route_tables=$(aws ec2 describe-route-tables --filters "Name=vpc-id,Values=$vpc_id" --query 'RouteTables[*].RouteTableId' --output text)
            
            # Split the route table IDs by tabs and process each one
            IFS=$'\t' read -r -a rt_ids <<< "$route_tables"
            for rt in "${rt_ids[@]}"; do
              if [[ -n "$rt" && "$rt" =~ ^rtb- ]]; then
                echo "Processing route table: $rt"
                
                # Check if it's the main route table
                main_assoc=$(aws ec2 describe-route-tables --route-table-ids "$rt" --query 'RouteTables[0].Associations[?Main==`true`].RouteTableAssociationId' --output text)
                if [[ -n "$main_assoc" ]]; then
                  echo "Route table $rt is main, creating temporary replacement..."
                  new_rt_id=$(aws ec2 create-route-table --vpc-id "$vpc_id" --query 'RouteTable.RouteTableId' --output text)
                  aws ec2 replace-route-table-association --association-id "$main_assoc" --route-table-id "$new_rt_id"
                  echo "Main route table replaced with $new_rt_id"
                fi
                
                # Delete all non-local routes
                aws ec2 describe-route-tables --route-table-ids "$rt" --query 'RouteTables[0].Routes[*].[DestinationCidrBlock,GatewayId]' --output text | while read -r cidr gateway_id; do
                  if [[ "$gateway_id" != "local" && -n "$gateway_id" ]]; then
                    echo "Deleting route: $cidr from route table: $rt"
                    aws ec2 delete-route --route-table-id "$rt" --destination-cidr-block "$cidr"
                  else
                    echo "Skipping route: $cidr (Gateway: $gateway_id)"
                  fi
                done
                
                # Disassociate all non-main associations
                aws ec2 describe-route-tables --route-table-ids "$rt" --query 'RouteTables[0].Associations[?Main==`false`].RouteTableAssociationId' --output text | while read -r assoc_id; do
                  if [[ -n "$assoc_id" ]]; then
                    echo "Disassociating route table: $rt (Assoc ID: $assoc_id)"
                    aws ec2 disassociate-route-table --association-id "$assoc_id"
                  fi
                done
                
                echo "Deleting route table: $rt"
                aws ec2 delete-route-table --route-table-id "$rt" || echo "Route table $rt could not be deleted (may still be associated)."
              else
                echo "Skipping invalid route table ID: $rt"
              fi
            done
            done
            
            # Delete non-default NACLs
            nacls=$(aws ec2 describe-network-acls --filters "Name=vpc-id,Values=$vpc_id" --query 'NetworkAcls[*].[NetworkAclId,IsDefault]' --output text)
            while read -r nacl_id is_default; do
              if [[ "$is_default" != "true" ]]; then
                echo "Deleting network ACL: $nacl_id"
                aws ec2 delete-network-acl --network-acl-id "$nacl_id"
              fi
            done
            
            # Delete the VPC
            echo "Deleting VPC: $vpc_id"
            aws ec2 delete-vpc --vpc-id "$vpc_id"
          done
        working-directory: ${{ github.workspace }}/${{ inputs.source_dir || 'infra/terraform/vpc' }}

      - name: Create VPC Infrastructure
        if: steps.check_vpc.outputs.VPC_EXISTS != 'true'
        run: |
          # Set environment variables
          ENVIRONMENT="${{ github.event.inputs.environment || 'dev' }}"
          
          # Configure VPC module
          cat > vpc.tfvars <<EOF
          environment = "${ENVIRONMENT}"
          name = "mlflow-vpc-${ENVIRONMENT}"
          vpc_cidr = "10.0.0.0/16"
          azs = ["us-east-1a", "us-east-1b", "us-east-1c"]
          public_subnet_cidrs = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
          private_subnet_cidrs = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]
          EOF
          
          # Initialize and apply VPC module
          terraform init
          terraform plan -out=vpc-plan
          terraform apply -auto-approve vpc-plan
        working-directory: ${{ github.workspace }}/${{ inputs.source_dir || 'infra/terraform/vpc' }}

      - name: Get VPC Outputs
        if: steps.check_vpc.outputs.VPC_EXISTS != 'true'
        id: vpc_outputs
        run: |
          outputs=$(terraform output -json)
          echo "VPC_ID=$(echo $outputs | jq -r '.vpc_id.value')" >> $GITHUB_OUTPUT
          echo "PUBLIC_SUBNET_IDS=$(echo $outputs | jq -r '.public_subnets.value | @json')" >> $GITHUB_OUTPUT
          echo "PRIVATE_SUBNET_IDS=$(echo $outputs | jq -r '.private_subnets.value | @json')" >> $GITHUB_OUTPUT
        working-directory: ${{ github.workspace }}/${{ inputs.source_dir || 'infra/terraform/vpc' }}

      - name: Configure MLFlow Terraform
        run: |
          # Set fallback values if inputs are not defined (non-manual runs)
          ENVIRONMENT="${{ github.event.inputs.environment || 'dev' }}"
          CLUSTER_NAME="mlflow-cluster-${ENVIRONMENT}"

      - name: Configure MLFlow Terraform
        run: |
          # Create terraform.tfvars using VPC outputs
          cat > terraform.tfvars <<EOF
          environment = "${{ github.event.inputs.environment || 'dev' }}"
          cluster_name = "mlflow-cluster-${{ github.event.inputs.environment || 'dev' }}"
          db_password = "${{ env.DB_PASSWORD }}"
          region = "${{ env.AWS_REGION }}"
          EOF
          
          # Initialize and plan
          terraform init
          terraform plan -out=tfplan
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Set VPC Variables
        run: |
          # Set VPC variables based on whether we created a new VPC or using existing
          if [ "${{ steps.check_vpc.outputs.VPC_EXISTS }}" = "true" ]; then
            echo "VPC_ID=${{ steps.check_vpc.outputs.VPC_ID }}" >> $GITHUB_ENV
            echo "PUBLIC_SUBNET_IDS=${{ steps.check_vpc.outputs.PUBLIC_SUBNET_IDS }}" >> $GITHUB_ENV
            echo "PRIVATE_SUBNET_IDS=${{ steps.check_vpc.outputs.PRIVATE_SUBNET_IDS }}" >> $GITHUB_ENV
          else
            echo "VPC_ID=${{ steps.vpc_outputs.outputs.VPC_ID }}" >> $GITHUB_ENV
            echo "PUBLIC_SUBNET_IDS=${{ steps.vpc_outputs.outputs.PUBLIC_SUBNET_IDS }}" >> $GITHUB_ENV
            echo "PRIVATE_SUBNET_IDS=${{ steps.vpc_outputs.outputs.PRIVATE_SUBNET_IDS }}" >> $GITHUB_ENV
          fi
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}

      - name: Terraform Apply
        if: ${{ env.TF_ACTION == 'apply' }}
        run: terraform apply -auto-approve tfplan
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Plan
        if: ${{ env.TF_ACTION == 'plan' }}
        run: terraform plan -out=tfplan
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Destroy
        if: ${{ env.TF_ACTION == 'destroy' }}
        run: terraform destroy -auto-approve
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Save Terraform State
        if: ${{ env.TF_ACTION == 'apply' }}
        uses: actions/upload-artifact@v4
        with:
          name: terraform-state
          path: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}/terraform.tfstate

      - name: Get Outputs
        if: ${{ env.TF_ACTION == 'apply' }}
        run: |
          terraform output -json > terraform-outputs.json
          cat terraform-outputs.json
        id: get_outputs
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Save Outputs
        if: ${{ env.TF_ACTION == 'apply' }}
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs
          path: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}/terraform-outputs.json

      - name: Cleanup
        if: ${{ env.TF_ACTION == 'destroy' }}
        run: |
          rm -f terraform.tfstate
          rm -f terraform.tfstate.backup
          rm -f terraform.tfvars
          rm -f terraform-outputs.json
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}
