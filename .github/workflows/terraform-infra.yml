name: Terraform Infrastructure

on:
  workflow_dispatch:
    inputs:
      recreate:
        description: 'Recreate existing resources if they exist'
        required: false
        default: false
        type: boolean
      action:
        description: 'Action to perform (plan/apply/destroy)'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply
          - destroy
      environment:
        description: 'Environment (dev/prod)'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - prod
      source_dir:
        description: 'Source directory for Terraform files'
        required: true
        default: 'infra/terraform'
        type: string
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

permissions:
  id-token: write
  contents: read
  actions: read

env:
  AWS_REGION: us-east-1
  TF_CLI_ARGS: "-parallelism=1"  # Lower parallelism to reduce API rate limit issues

jobs:
  terraform:
    name: Terraform
    runs-on: ubuntu-latest
    env:
      TF_ACTION: ${{ github.event.inputs.action || 'plan' }}
      TF_SOURCE_DIR: ${{ github.event.inputs.source_dir || 'infra/terraform' }}
      ENVIRONMENT: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.6.0

      - name: Create terraform.tfvars
        run: |
          cat > terraform.tfvars <<EOF
          environment = "${{ env.ENVIRONMENT }}"
          cluster_name = "mlflow-cluster-${{ env.ENVIRONMENT }}"
          db_password = "temporarily_replaced_password"
          region = "${{ env.AWS_REGION }}"
          EOF
          # Replace the placeholder with actual password using sed to avoid GitHub Actions workflow syntax issues
          sed -i "s/temporarily_replaced_password/${{ secrets.DB_PASSWORD }}/g" terraform.tfvars
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Init
        run: terraform init -upgrade
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      # Only run imports when action is "apply" and recreate is false
      - name: Import existing resources
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.recreate != true }}
        run: |
          set +e  # Don't exit on error
          echo "Starting resource import for environment: ${{ env.ENVIRONMENT }}"
          
          # Set existing_resources to true in terraform.tfvars to avoid recreation
          echo "existing_resources = true" >> terraform.tfvars
          
          # Import S3 Bucket
          echo "Checking for S3 bucket: mlflow-backend-${{ env.ENVIRONMENT }}"
          aws s3api head-bucket --bucket mlflow-backend-${{ env.ENVIRONMENT }} 2>/dev/null
          if [ $? -eq 0 ]; then
            echo "Importing S3 bucket: mlflow-backend-${{ env.ENVIRONMENT }}"
            terraform import -var-file=terraform.tfvars module.s3.aws_s3_bucket.mlflow_bucket[0] mlflow-backend-${{ env.ENVIRONMENT }}
            echo "S3 bucket import result: $?"
          else
            echo "S3 bucket not found, skipping import"
          fi
          
          # Import IAM User
          echo "Checking for IAM user: mlflow-user"
          USER_CHECK=$(aws iam get-user --user-name mlflow-user 2>&1)
          if ! echo "$USER_CHECK" | grep -q "NoSuchEntity"; then
            echo "Importing IAM user: mlflow-user"
            terraform import -var-file=terraform.tfvars module.s3.aws_iam_user.mlflow_user[0] mlflow-user
            echo "IAM user import result: $?"
          else
            echo "IAM user not found, skipping import"
          fi
          
          # Import IAM Policy
          echo "Checking for IAM policy: mlflow-s3-access"
          POLICY_ARN=$(aws iam list-policies --query "Policies[?PolicyName=='mlflow-s3-access'].Arn" --output text)
          if [ -n "$POLICY_ARN" ] && [ "$POLICY_ARN" != "None" ]; then
            echo "Importing IAM policy: $POLICY_ARN"
            terraform import -var-file=terraform.tfvars module.s3.aws_iam_policy.mlflow_s3_policy[0] "$POLICY_ARN"
            echo "IAM policy import result: $?"
          else
            echo "IAM policy not found, skipping import"
          fi
          
          # Import DB Subnet Group
          echo "Checking for DB subnet group: mlflow-db-subnet-group-${{ env.ENVIRONMENT }}"
          DB_SUBNET_CHECK=$(aws rds describe-db-subnet-groups --db-subnet-group-name mlflow-db-subnet-group-${{ env.ENVIRONMENT }} 2>&1)
          if ! echo "$DB_SUBNET_CHECK" | grep -q "DBSubnetGroupNotFoundFault"; then
            echo "Importing DB subnet group: mlflow-db-subnet-group-${{ env.ENVIRONMENT }}"
            terraform import -var-file=terraform.tfvars module.rds.aws_db_subnet_group.mlflow[0] mlflow-db-subnet-group-${{ env.ENVIRONMENT }}
            echo "DB subnet group import result: $?"
          else
            echo "DB subnet group not found, skipping import"
          fi
          
          # Find existing VPC
          echo "Checking for existing VPCs"
          EXISTING_VPC=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=mlflow-vpc" --query "Vpcs[0].VpcId" --output text)
          if [ -n "$EXISTING_VPC" ] && [ "$EXISTING_VPC" != "None" ]; then
            echo "Found existing VPC: $EXISTING_VPC"
            # Add VPC ID to terraform.tfvars to use existing VPC
            echo "vpc_id = \"$EXISTING_VPC\"" >> terraform.tfvars
          else
            echo "No existing VPC found matching mlflow-vpc"
          fi
          
          # Import CloudWatch Log Group
          echo "Checking for CloudWatch log group: /aws/eks/mlflow-cluster-${{ env.ENVIRONMENT }}/cluster"
          CW_LOG_CHECK=$(aws logs describe-log-groups --log-group-name-prefix /aws/eks/mlflow-cluster-${{ env.ENVIRONMENT }}/cluster --query "logGroups[0].logGroupName" --output text 2>&1)
          if [ -n "$CW_LOG_CHECK" ] && [ "$CW_LOG_CHECK" != "None" ]; then
            echo "Importing CloudWatch log group: $CW_LOG_CHECK"
            terraform import -var-file=terraform.tfvars module.eks.aws_cloudwatch_log_group.this[0] "$CW_LOG_CHECK"
            echo "CloudWatch log group import result: $?"
          else
            echo "CloudWatch log group not found, skipping import"
          fi
          
          # Import KMS key and alias
          echo "Checking for KMS key with alias: alias/eks/mlflow-cluster-${{ env.ENVIRONMENT }}"
          KMS_KEY_ID=$(aws kms list-aliases --query "Aliases[?AliasName=='alias/eks/mlflow-cluster-${{ env.ENVIRONMENT }}'].TargetKeyId" --output text)
          if [ -n "$KMS_KEY_ID" ] && [ "$KMS_KEY_ID" != "None" ]; then
            echo "Importing KMS key: $KMS_KEY_ID"
            terraform import -var-file=terraform.tfvars module.eks.aws_kms_key.this[0] "$KMS_KEY_ID"
            echo "KMS key import result: $?"
            
            echo "Importing KMS alias: alias/eks/mlflow-cluster-${{ env.ENVIRONMENT }}"
            terraform import -var-file=terraform.tfvars module.eks.aws_kms_alias.this[0] "alias/eks/mlflow-cluster-${{ env.ENVIRONMENT }}"
            echo "KMS alias import result: $?"
          else
            echo "KMS key/alias not found, skipping import"
          fi
          
          echo "Import operations completed"
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      # If action is apply and recreate is true, run "terraform state rm" on resources
      - name: Remove resources from state if recreating
        if: ${{ github.event.inputs.action == 'apply' && github.event.inputs.recreate == true }}
        run: |
          echo "Removing resources from state for recreation"
          terraform state list | grep -E "(aws_s3_bucket|aws_iam_user|aws_iam_policy|aws_db_subnet_group|aws_cloudwatch_log_group|aws_kms_key|aws_kms_alias)" || echo "No matching resources in state"
          terraform state list | grep -E "(aws_s3_bucket|aws_iam_user|aws_iam_policy|aws_db_subnet_group|aws_cloudwatch_log_group|aws_kms_key|aws_kms_alias)" | xargs -r terraform state rm
          
          # Remove existing_resources = true from terraform.tfvars if it exists
          sed -i '/existing_resources = true/d' terraform.tfvars
          # Add existing_resources = false to terraform.tfvars
          echo "existing_resources = false" >> terraform.tfvars
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Plan
        if: ${{ env.TF_ACTION == 'plan' }}
        run: terraform plan -input=false -var-file=terraform.tfvars
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Apply
        if: ${{ env.TF_ACTION == 'apply' }}
        run: |
          # First do a plan to check for errors
          terraform plan -input=false -var-file=terraform.tfvars -detailed-exitcode || true
          
          # If recreating resources, use more permissive error handling
          if [[ "${{ github.event.inputs.recreate }}" == "true" ]]; then
            echo "Running in recreate mode - will attempt to create new resources"
            # Try to apply with -target flags for resources that may already exist
            terraform apply -auto-approve -input=false -var-file=terraform.tfvars || echo "Some resources may have failed to create due to pre-existence."
          else
            echo "Running in normal mode - using existing resources where possible"
            terraform apply -auto-approve -input=false -var-file=terraform.tfvars || {
              echo "Apply failed, checking specific errors..."
              # Check for VPC limit error and try again with an existing VPC if needed
              if grep -q "VpcLimitExceeded" terraform.tfstate.backup; then
                echo "VPC limit reached. Trying to find existing VPC to use..."
                EXISTING_VPC=$(aws ec2 describe-vpcs --filters "Name=isDefault,Values=true" --query "Vpcs[0].VpcId" --output text)
                if [ -n "$EXISTING_VPC" ] && [ "$EXISTING_VPC" != "None" ]; then
                  echo "Using default VPC: $EXISTING_VPC"
                  echo "vpc_id = \"$EXISTING_VPC\"" >> terraform.tfvars
                  terraform apply -auto-approve -input=false -var-file=terraform.tfvars
                fi
              else
                echo "Apply failed with errors that cannot be automatically fixed."
                exit 1
              fi
            }
          fi
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}

      - name: Terraform Destroy
        if: ${{ env.TF_ACTION == 'destroy' }}
        run: terraform destroy -auto-approve -input=false -var-file=terraform.tfvars
        working-directory: ${{ github.workspace }}/${{ env.TF_SOURCE_DIR }}